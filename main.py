import os 
import streamlit as st
from langchain_core.messages import AIMessage , HumanMessage
from agent_graph import graph 

def main() : 
    
    st.set_page_config(page_title="Hansol Guard", 
                        page_icon=":construction:", 
                        layout="centered",)
        
    st.title("Hansol Guard QA ChatBot :construction:")

    with st.sidebar : 
        st.subheader("ì‚¬ê³  ì •ë³´ ì…ë ¥ë€")
        st.markdown(" ")
        work_clf = st.text_input("**âœ… ê³µì¢…**", placeholder = "ex) ì² í°ì½˜í¬ë¦¬íŠ¸ê³µì‚¬")
        work_process = st.text_input("**âœ… ì‘ì—… í”„ë¡œì„¸ìŠ¤**", placeholder = "ex) ì ˆë‹¨ì‘ì—…, íƒ€ì„¤ì‘ì—…")
        accident_object = st.text_input("**âœ… ì‚¬ê³ ê°ì²´**", placeholder = "ex) ê³µêµ¬ë¥˜")
        human_accident = st.text_input("**âœ… ì¸ì ì‚¬ê³ **", placeholder = "ex) ë¼ì„")
        property_accident = st.text_input("**âœ… ë¬¼ì ì‚¬ê³ **", placeholder = "ex) ì—†ìŒ")
            
    # ì„¸ì…˜ìƒíƒœ ì´ˆê¸°í™” 
    if 'message' not in st.session_state : 
        st.session_state["messages"] = [
            AIMessage(content = "ì•ˆë…•í•˜ì„¸ìš”! ê±´ì„¤ì‚¬ê³  ëŒ€ì‘ì±… AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ê³  ìƒí™©ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”! ")
        ]
        
    # ë©”ì„¸ì§€ íˆìŠ¤í† ë¦¬ í‘œì‹œ 
    for msg in st.session_state.messages :
        if isinstance(msg , AIMessage) : 
            st.chat_message("assistant").write(msg.content)
        if isinstance(msg , HumanMessage) :
            st.chat_message("user").write(msg.content)
            
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ 
    if prompt := st.chat_input("ì‚¬ê³  ì›ì¸ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.") : 
        st.session_state.messages.append(HumanMessage(content = prompt)) 
        
        # ì‚¬ê³  ì •ë³´ì™€ ê²°í•© 
        accicdent_prompt = f"""
        ê³µì¢… : {work_clf}
        ì‘ì—…í”„ë¡œì„¸ìŠ¤ : {work_process}
        ì‚¬ê³ ê°ì²´ : {accident_object}
        ì¸ì ì‚¬ê³  : {human_accident}
        ë¬¼ì ì‚¬ê³  : {property_accident}
        ì‚¬ê³ ì›ì¸ : {prompt}\n
        ìœ„ ì‚¬ê³  ìƒí™©ì— ëŒ€í•œ ì¬ë°œë°©ì§€ ëŒ€ì±… ë° í–¥í›„ì¡°ì¹˜ê³„íšì€ ë¬´ì—‡ì¸ê°€ìš”? 
        """
        
        st.chat_message("user").write(accicdent_prompt)
        
        question_list = [ work_clf, work_process, accident_object, human_accident, property_accident, prompt ]

        # AI ì‘ë‹µì²˜ë¦¬ 
        with st.chat_message("assistant") : 
            
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state = {
                # ê³µì¢…, ì‘ì—…í”„ë¡œì„¸ìŠ¤, ì‚¬ê³ ê°ì²´, ì¸ì ì‚¬ê³ , ë¬¼ì ì‚¬ê³ , ì‚¬ê³ ì›ì¸
                "question" : question_list , 
                "pdf_prompt" : "" ,  
                "csv_prompt" : "" ,
                "pdf_docs" : [] ,
                "csv_docs" : [] , 
                "think_response" : "",
                "final_response" : "",
                "generator" : None
            }
            
            thinking_placeholder = st.empty()
            response_placeholder = st.empty()
            
            try : 
                # ê·¸ë˜í”„ ì‹¤í–‰ ë° ìƒíƒœ ì—…ë°ì´íŠ¸ (ë…¸ë“œ ì‹¤í–‰ê²°ê³¼ë¥¼ step ìœ¼ë¡œ ë°›ì•„ ì¤Œ)
                for step in graph.stream(initial_state) :
                    
                    # í˜„ì¬ ë‹¨ê³„ í‘œì‹œ(node_name : ë…¸ë“œ ì´ë¦„ , state : ë…¸ë“œ ê²°ê³¼ê°’ )
                    for node_name , state in step.items() : 
                        
                        if node_name == "retrieve": 
                            with st.expander("ğŸ‘·ğŸ¼ ì˜ˆì‹œ ê²€ìƒ‰ ê²°ê³¼") : 
                                for i , result in enumerate(state["csv_docs"]) :
                                    st.write(f"{result}")
                                    
                            with st.expander("ğŸ” PDF ê²€ìƒ‰ ê²°ê³¼") :
                                for i , result in enumerate(state["pdf_docs"]) :
                                    st.write(f"{result}") 
                        
                        if node_name == "generate":
                            if "generator" in state:
                                
                                generator = state["generator"]
                                
                                thinking_content = ""
                                response_content = ""
                                
                                for chunk in generator(): #streaming
                                    thinking_content = chunk["think_response"]
                                    response_content = chunk["final_response"]
                                    
                                    with st.expander("ğŸ’­ ì‚¬ê³  ê³¼ì •", expanded=False):
                                        thinking_placeholder.markdown(thinking_content)
                                    
                                    # ìµœì¢… ì‘ë‹µ ì—…ë°ì´íŠ¸ (mode_changeê°€ Trueì¼ ë•Œ í‘œì‹œ ì‹œì‘)
                                    if chunk["mode_change"] or response_content:
                                        response_placeholder.markdown(response_content)
                                
                                # ìµœì¢… ì‘ë‹µ ì €ì¥
                                st.session_state.messages.append(AIMessage(content=response_content))
                                
            except Exception as e :
                st.error(f"Error ë°œìƒ : {str(e)}")

    # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼ 
    if st.button("ëŒ€í™” ê¸°ë¡ ì§€ìš°ê¸°") : 
        
        st.session_state.messages = [
            AIMessage(content = "ì•ˆë…•í•˜ì„¸ìš”! ê±´ì„¤ì‚¬ê³  ëŒ€ì‘ì±… AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ê³  ìƒí™©ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”! ")
        ]
        
        # ì‚¬ì´ë“œë°” ì…ë ¥ê°’ ì´ˆê¸°í™”
        keys_to_clear = ["work_clf" , "work_process", "accident_object", "human_accident", "property_accident"]
        
        for key in keys_to_clear:
            if key in st.session_state:
                del st.session_state[key]  
                
        st.rerun() # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ 
    
    
if __name__ == "__main__" :
    main()